Pandas has two types of data structures. 

1)	Series- its one-dimensional array with indexes, it store a single column of row data in a data frame
2)	Data frame- it is a tabular spreadsheet like structure representing rows each of which contains one or multiple columns. 
  1d array- same type of data 
2d array- hold different types of pf data. 

------------------------ PANDAS NOTES -----------------
// IMPORT THE PANDAS AND NUMPY 
import pandas as pd.
import NumPy as np

/ Create a dictionary

dict1={"name”: ['ankur','ashish','rohit','raghav'],"marks":[90,80,97,89]
      ,"city":['Varanasi','Benares','Kashi','Delhi']}

// into a data frame 
df=pd.DataFrame(dict1)

// for printing data just print the variable name 
Df

// importing into csv

df.to_csv('marks_friends.csv')

// for removing index like 0,1,2 use index=false.

df.to_csv('marks_friends_noindex.csv',index=False)

// to get the only top 2 or last three values use head and tail functions .
TAIL>>> it will the values from bottom 
df.tail(2)  --- bottom 2 values 
df.tail(-6)  -- it will left the top 6 values an return after the indexing of 7 to next next


HEAD)>>>> it will return the top values 
df.head(2) return the top 2 
Notes::>>  By default head return top 5 values 
df.head(-5)  it will return the all values except the last 8 values 
// to get the statistical values but it only valid on numerical values 

df.describe()

it will show s u
1)count
2)means
3)std(standard deviation)
4)min
5)25%
6)50%
7)75%
8)max

//// ------  to know the data types of files write  files.dtypes()
Sales.dtypes



/-------------------------   accessing from your created folder or physically present files ------
// for reading the file 
Create a variable and write var=pd.read_csv(“file name .extension”)
sales=pd.read_csv('SalesData.csv')
sales // it will show the values. 

// as we know that there are so many entity in a table to access particular rows jus write 
Var[row]
Sales[‘revenue’]// to access revenue row.

// to access 0th index of that entity
Write sales[‘revenues’][0]// to access revenues having index 0;

// to change the value of that index 
Sales[‘revenue’][0]=900// changing the value to 900

// to see the changes values in csv
sales.to_csv('SalesData')

// to change the indexing 

sales.index=['one','two','three','fourth']


/// new parts begins -----------------

// for executing series 

ser=pd.Series(np.random.rand(22))

// to get the indexing 
newdf.index

// to get in the arrays values write ---------- filename.to_numpy()
newdf.to_numpy()
// to ttranspose the columns and rows use the function 'T" like rows to column and colum to rows 

newdf.T
// to accesing the rows in descending orders use 
newdf.sort_index(axis=1,ascending =False)
here 
newdf is the var
sort_index is the function 
axis =1 is rows and axis =0 means column
ascending =False means ascending will not be allowed


// to create a view use the variable 
Notes ::>> but in views if we modify or update some change in the new table than the original one will 
also be modified 
newdf2=newdf

// to create the copy of the table 
Notes::>> it will not change the previous or original table 

newdf2=newdf.copy()

//  LOC function 

newdf.loc[0,0]=76
newdf.columns=list('ABCDE')
//to drop the columns use the 
newdf=newdf.drop('E',axis=1)    we will drop the column E and axis =1 means the column 


// to access the specified rows and columns use 

newdf.loc[[1,3],['A','B']]  # for the given rows 
fetch the values of rows a,b and colmun 1,3

# # for the all columns
newdf.loc[[1,2],:]

# query like sql for accesing the columns based on conditions 

newdf.loc[newdf['A']<0.8] # return the columns whose values is gretarer than 0.8

## 
rev=newdf.loc[(newdf['A']<0.3) & (newdf['B']>0.6)]# selecting values whose values are greater 
#than 0.3 in clumn A and 0.6 in column B 
# we cant use 'and' in char use & this sign 


NOtes """  ----------len(rev) # to count the column

# to use the name for accessing using loc 
# to use the number for accessing use iloc
newdf.iloc[0,3]

# as we know to drop the column we have to write the variables like 
#newdf=newdf.drop([2])
#but to drop the values without using the new variable use the inplace =TRUE
# inplace to modify the original tables or datas
newdf.drop(['A','D'],axis=1,inplace=True)
